{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "z8RcTq80em7O",
      "metadata": {
        "id": "z8RcTq80em7O"
      },
      "source": [
        "# **Information**\n",
        "\n",
        "**• Members:** 사푸트라 (Saputra Rizky Johan), 바트오르식 (Butemj Bat-Orshikh), 쉬슈잔 (Shu Xian Chow)\n",
        "\n",
        "**• Institution:** Seoul National University, South Korea\n",
        "\n",
        "**• Course:** 2025-2 Introduction to Natural Language Processing (001)\n",
        "\n",
        "**• Instructors:** 황승원 (Prof), 김종윤(TA), 한상은 (TA)\n",
        "\n",
        "**• Project:** Classifier-Guided Politeness Rewriting via Span Detection and Controlled Text Generation\n",
        "\n",
        "**• Corpus:** Stanford Politeness Corpus (Convokit)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3834e0ef",
      "metadata": {
        "id": "3834e0ef"
      },
      "source": [
        "\n",
        "# **Politeness Rewriter - Colab Runner**\n",
        "\n",
        "**• Note:** This notebook runs the **politeness-rewriter** project end-to-end in Google Colab with the current version pins:\n",
        "- Keep **NumPy ≥ 2** (for spaCy/thinc/Convokit)\n",
        "- Pin **Transformers 4.44.2** (supports `evaluation_strategy`)\n",
        "- Keep **pandas==2.2.2** (to match google-colab)\n",
        "- Use **spacy 3.8.x** + **Convokit 3.4.1** (Py3.12-friendly wheels)\n",
        "\n",
        "**• Pipeline:** Drive mount → unzip → fix package layout → install deps → download data → train classifier → sanity infer → rewrite → quick eval → *(optional)* Gradio demo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6kbNg3ByP711",
      "metadata": {
        "id": "6kbNg3ByP711"
      },
      "source": [
        "# **Case 1. Run via Google Drive**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A4vposfcRGFJ",
      "metadata": {
        "id": "A4vposfcRGFJ"
      },
      "source": [
        "## **1.1. Check GPU and Mount Drive**\n",
        "\n",
        "**• Purpose:**\n",
        "- Execute the associated step in the Colab workflow and detect the available GPU.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "663c6c13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "663c6c13",
        "outputId": "998a294a-4756-4164-a366-7427e07462cb"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Check the available GPU\n",
        "!nvidia-smi || echo \"No GPU visible (training will still work, just slower).\"\n",
        "\n",
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZuV0KYJpShJ1",
      "metadata": {
        "id": "ZuV0KYJpShJ1"
      },
      "source": [
        "## **1.2. Locate and load the project file**\n",
        "\n",
        "**• Purpose:**\n",
        "- Change the working directory and prepare project paths for running.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes).\n",
        "- Adjusts the project name accordingly if the file is in a different name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5f2bd2b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f2bd2b9",
        "outputId": "456394a5-8f23-4488-dbca-1a99e692011d"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Declare the names of the zip file in your drive (Adjust if necessary)\n",
        "ZIP_CANDIDATES = [\n",
        "    \"/content/drive/MyDrive/politeness-rewriters.zip\",\n",
        "    \"/content/drive/MyDrive/politeness-rewritters.zip\",\n",
        "    \"/content/drive/MyDrive/Downloads/politeness-rewriter.zip\",\n",
        "    \"/content/drive/MyDrive/Downloads/politeness-rewritter.zip\",\n",
        "    \"/content/drive/MyDrive/politeness-rewriter.zip\",\n",
        "    \"/content/drive/MyDrive/politeness-rewritter.zip\",\n",
        "]\n",
        "\n",
        "# Locate the politeness rewriter zip file\n",
        "zip_path = None\n",
        "import os\n",
        "for cand in ZIP_CANDIDATES:\n",
        "    if os.path.exists(cand):\n",
        "        zip_path = cand; break\n",
        "if zip_path is None:\n",
        "    raise FileNotFoundError(\"Could not find the project ZIP. Set `zip_path` manually to its location in Drive.\")\n",
        "\n",
        "# Display the zip file and its path\n",
        "print(\"Using ZIP:\", zip_path)\n",
        "\n",
        "# Unzip the file into the content directory (Adjust if necessary)\n",
        "%cd /content\n",
        "!unzip -o \"$zip_path\" -d /content\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HLT7CuA5T9rA",
      "metadata": {
        "id": "HLT7CuA5T9rA"
      },
      "source": [
        "## **1.3. Project Normalization**\n",
        "\n",
        "**• Purpose:**\n",
        "- Normalize the project folder name, ensure the src is a package and remove and bundled env/.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes).\n",
        "- Adjusts the project name accordingly if the file is in a different name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "77137333",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77137333",
        "outputId": "c8190014-d8ff-4259-c24f-37725ffd2c21"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Setup the necessary modules or packages\n",
        "import os, shutil, sys\n",
        "\n",
        "# Normalize the project folder name\n",
        "proj_path = None\n",
        "for cand in [\"/content/politeness-rewriters\", \"/content/politeness-rewritters\"]:\n",
        "    if os.path.isdir(cand):\n",
        "        proj_path = cand; break\n",
        "if proj_path is None:\n",
        "    for root, dirs, files in os.walk(\"/content\"):\n",
        "        if \"src\" in dirs and \"requirements.txt\" in files:\n",
        "            proj_path = root; break\n",
        "if proj_path is None:\n",
        "    raise RuntimeError(\"Could not locate the project folder after unzipping.\")\n",
        "\n",
        "# Rename the misspelling to a canonical folder\n",
        "if proj_path.endswith(\"politeness-rewritters\"):\n",
        "    target = \"/content/politeness-rewriters\"\n",
        "    if os.path.isdir(target):\n",
        "        shutil.rmtree(target, ignore_errors=True)\n",
        "    os.rename(proj_path, target)\n",
        "    proj_path = target\n",
        "\n",
        "print(\"Project path:\", proj_path)\n",
        "%cd \"$proj_path\"\n",
        "\n",
        "# Remove the bundled venv if present\n",
        "if os.path.isdir(\"env\"):\n",
        "    print(\"Removing bundled env/\"); shutil.rmtree(\"env\", ignore_errors=True)\n",
        "\n",
        "# Ensure src is a package\n",
        "os.makedirs(\"src\", exist_ok=True)\n",
        "if os.path.exists(\"src/init.py\") and not os.path.exists(\"src/__init__.py\"):\n",
        "    os.rename(\"src/init.py\", \"src/__init__.py\")\n",
        "if not os.path.exists(\"src/__init__.py\"):\n",
        "    open(\"src/__init__.py\", \"a\").close()\n",
        "print(\"src/__init__.py OK\")\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iW-mv3i_VXIX",
      "metadata": {
        "id": "iW-mv3i_VXIX"
      },
      "source": [
        "## **1.4. Install Dependencies**\n",
        "\n",
        "**• Purpose:**\n",
        "- Install the necessary Python dependencies required to load and run the Politeness Rewriter project.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes).\n",
        "- Adjusts the dependencies only when it is necessary. Otherwise, keep the current dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "de00fa20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de00fa20",
        "outputId": "40173412-0edc-407e-b75e-f694a183d676"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "%%bash\n",
        "set -e\n",
        "\n",
        "# Modernize toolchain\n",
        "python -m pip install -U pip setuptools wheel\n",
        "\n",
        "# Foundation pins (Keep NumPy >=2 and pandas==2.2.2 for Colab harmony)\n",
        "python -m pip install -U \"numpy>=2.0,<3\" \"pandas==2.2.2\"\n",
        "\n",
        "# Core HF stack (Transformers 4.44.2 supports `evaluation_strategy`)\n",
        "python -m pip install -U \"transformers==4.44.2\" \"tokenizers==0.19.1\" \"accelerate==0.33.0\"\n",
        "\n",
        "# NLP, metrics, utils\n",
        "python -m pip install -U \"datasets>=2.20.0\" \"sentence-transformers>=3.0.1\"   \"scikit-learn>=1.3.0\" \"tqdm>=4.66.0\" \"bert-score>=0.3.13\" \"evaluate>=0.4.1\"   \"gradio>=4.36.1\" \"nltk>=3.8.1\" \"pyyaml>=6.0\"\n",
        "\n",
        "# Spacy 3.8.x (Py3.12 wheels) + Convokit 3.4.1\n",
        "python -m pip install -U \"spacy>=3.8,<3.9\" \"convokit==3.4.1\"\n",
        "\n",
        "# If repo has requirements.txt, install it without deps so we don't downgrade the pinned stack.\n",
        "if [ -f requirements.txt ]; then\n",
        "  python -m pip install --no-deps -r requirements.txt || true\n",
        "fi\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7Mq4-yE5WPmd",
      "metadata": {
        "id": "7Mq4-yE5WPmd"
      },
      "source": [
        "## **1.5. Cache the HuggingFace models (Optional)**\n",
        "\n",
        "**• Purpose:**\n",
        "- cache HF models to Drive to avoid redownloading. However, this step is optional.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "03d8f735",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03d8f735",
        "outputId": "c2e39dd2-ed6b-4bdb-c596-f9f6c1345515"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Setup the necessary modules or packages\n",
        "import os\n",
        "\n",
        "# Declare the directory for caching the HF models into Drive\n",
        "os.environ[\"HF_HOME\"] = \"/content/drive/MyDrive/hf_cache\"\n",
        "os.environ[\"TRANSFORMERS_CACHE\"] = \"/content/drive/MyDrive/hf_cache\"\n",
        "os.makedirs(os.environ[\"HF_HOME\"], exist_ok=True)\n",
        "print(\"HF cache:\", os.environ[\"HF_HOME\"])\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OSC2ZRIqXI_7",
      "metadata": {
        "id": "OSC2ZRIqXI_7"
      },
      "source": [
        "## **1.6. Patching to utilize the dataset keys**\n",
        "\n",
        "**• Purpose:**\n",
        "- Patch the dataset directory, specifically src/download_data.py, in order to to use the correct dataset key.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "wjug4EvMK70o",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjug4EvMK70o",
        "outputId": "adc6de52-ff2c-4e1d-b723-04a27fa10e2a"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Setup the necessary modules or packages\n",
        "from pathlib import Path\n",
        "\n",
        "# Declare the directory and associated paths\n",
        "p = Path(\"src/download_data.py\")\n",
        "s = p.read_text()\n",
        "\n",
        "# Patch the download_data.py module\n",
        "s2 = s.replace('download(\"stanford-politeness-corpus\")',\n",
        "               'download(\"stack-exchange-politeness-corpus\")')\n",
        "p.write_text(s2)\n",
        "print(\"Patched download_data.py -> 'stack-exchange-politeness-corpus'\")\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-imS50mRYFd_",
      "metadata": {
        "id": "-imS50mRYFd_"
      },
      "source": [
        "## **1.7. Download the Stanford Politeness data via ConvoKit**\n",
        "\n",
        "**• Purpose:**\n",
        "- Run download_data.py with the stack-exchange-politeness-corpus.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "29e3e7b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29e3e7b5",
        "outputId": "5ed2073a-7a37-4a80-9530-ead383a352ab"
      },
      "outputs": [],
      "source": [
        "\n",
        "## --------------------------------------- START ---------------------------------------\n",
        "# Download the Stanford Politeness data and run the dataset loader for training\n",
        "%cd \"$proj_path\"\n",
        "!python src/download_data.py\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DYOLNIprYnik",
      "metadata": {
        "id": "DYOLNIprYnik"
      },
      "source": [
        "## **1.8. Training the classifier**\n",
        "\n",
        "**• Purpose:**\n",
        "- Train the classifier through classifier_train.py with the training parameters (adjust the number of epochs, batch size and learning rate for better results)\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes).\n",
        "- Adjust higher number of epochs and controlled learning rate (preferrably lower if the number of epochs is high) for better results without overfitting the data.\n",
        "- If there is an environment clash or error, please make sure to uninstall peft before training the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "z5BoLWUsbW9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5BoLWUsbW9a",
        "outputId": "f16179a2-2c59-4d1b-853b-7122b351c3bd"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "32c9fd1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32c9fd1e",
        "outputId": "523ab028-7f04-41b5-fd16-05adfffe72b8"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Train the classifier (Please adjust the parameters for better training results)\n",
        "%cd \"$proj_path\"\n",
        "!python src/classifier_train.py \\\n",
        "  --data_path data/train.jsonl \\\n",
        "  --save_dir out/classifier/model \\\n",
        "  --epochs 5 \\\n",
        "  --batch_size 16 \\\n",
        "  --lr 2e-5\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zA1yQ9TJZowQ",
      "metadata": {
        "id": "zA1yQ9TJZowQ"
      },
      "source": [
        "## **1.9. Run inference and sanity check**\n",
        "\n",
        "**• Purpose:**\n",
        "- Run the inference and execute sanity checks from the training results through the classifier_infer.py module.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "66e44325",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66e44325",
        "outputId": "54c43e1d-72c7-4364-8b89-4f0b55a728b3"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# 3) Quick inference sanity check\n",
        "%cd \"$proj_path\"\n",
        "!python src/classifier_infer.py --text \"send me the report now\"\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DvIzLaZAames",
      "metadata": {
        "id": "DvIzLaZAames"
      },
      "source": [
        "## **1.10. End-to-end rewriting**\n",
        "\n",
        "**• Purpose:**\n",
        "- Rewrite the sample input with the outputs using the trained classifier (Adjust the training parameters to achieve the best end to end results) through the pipeline.py module.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a9d8ad1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9d8ad1e",
        "outputId": "d43c64df-a531-4d4d-fefb-582aafa1e442"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Execute the end-to-end rewriting\n",
        "%cd \"$proj_path\"\n",
        "!python src/pipeline.py --text \"send me the report now asap\"\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rNhsJaXebOVV",
      "metadata": {
        "id": "rNhsJaXebOVV"
      },
      "source": [
        "## **1.11. Evaluate the model with samples**\n",
        "\n",
        "**• Purpose:**\n",
        "- Evaluate the dataset with a specified number of samples (Set more samples for more coherent results) through the eval.py module.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes).\n",
        "- Adjust the number of samples for better coherence and accuracy (higher number of samples is preferred)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d943248e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d943248e",
        "outputId": "4c6c3cfd-d3d9-403b-a56c-6d94742c5621"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Evaluate the model with the specified number of samples\n",
        "%cd \"$proj_path\"\n",
        "!python src/eval.py --n 20 --save_csv out/eval_samples.csv\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tM6bwKAEcBvR",
      "metadata": {
        "id": "tM6bwKAEcBvR"
      },
      "source": [
        "## **1.12. Lauch the gradio demo**\n",
        "\n",
        "**• Purpose:**\n",
        "- Launching a gradio demo as a visualizer and actual running with customized or personalized sentences via the app.py module.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes).\n",
        "- Execute the app via terminal using cd politeness-rewriters (or other directory names) and python app.py for retrieving the public url host."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "T8zrX3-Wd8Lj",
      "metadata": {
        "id": "T8zrX3-Wd8Lj"
      },
      "outputs": [],
      "source": [
        "!pip install -q \"gradio>=4.0.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "dd5bd6d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd5bd6d2",
        "outputId": "d87d4400-feff-463d-927d-656026480580"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Launch the Gradio demo\n",
        "%cd \"$proj_path\"\n",
        "!python app.py\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ewUm6pDNc92J",
      "metadata": {
        "id": "ewUm6pDNc92J"
      },
      "source": [
        "# **Case 2. Visual Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j8nu-_9Vf8xv",
      "metadata": {
        "id": "j8nu-_9Vf8xv"
      },
      "source": [
        "## **2.1. Load the Stanford Dataset**\n",
        "\n",
        "**• Purpose:**\n",
        "- Access and load the Standford dataset for overview of the sample sentences that is used for this project.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes).\n",
        "- Add or adjust any file names if necessary (Make sure to document if changes is made to GitHub)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48swF6WUf8_S",
      "metadata": {
        "id": "48swF6WUf8_S"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Setup the necessary modules or packages\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Define the path of the dataset (Adjust if necessary)\n",
        "DATA_PATH = \"/content/politeness-rewriters/data/stanford_politeness.jsonl\"\n",
        "\n",
        "# Read the JSONL\n",
        "records = []\n",
        "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if line:  # Skip any empty lines\n",
        "            records.append(json.loads(line))\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(records)\n",
        "\n",
        "# Load the dataset\n",
        "print(\"Rows:\", len(df))\n",
        "print(\"Columns:\", list(df.columns))\n",
        "df.head() # Adjust the number of data if necessary\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zR-bgHbrurUa",
      "metadata": {
        "id": "zR-bgHbrurUa"
      },
      "source": [
        "## **2.2. Load the Image of the Stanford Dataset Preview**\n",
        "\n",
        "**• Purpose:**\n",
        "- Load the image of the stanford dataset, partly for documentation and presentation purposes.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes).\n",
        "- Add or adjust any file names if necessary (Make sure to document if changes is made to GitHub)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89RJkJ_mroBb",
      "metadata": {
        "id": "89RJkJ_mroBb"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Setup the necessary modules or packages\n",
        "!pip install dataframe-image\n",
        "import pandas as pd\n",
        "import dataframe_image as dfi\n",
        "\n",
        "# Declare the sample DataFrame\n",
        "sample_df = df.head(10) # Adjust the number of data if necessary\n",
        "\n",
        "# Stylized the layout of the data\n",
        "styled = (\n",
        "    sample_df.style.set_properties(**{\n",
        "        \"background-color\": \"#f9f9f9\",\n",
        "        \"border-color\": \"black\",\n",
        "        \"color\": \"black\",\n",
        "        \"border-width\": \"1px\",\n",
        "        \"border-style\": \"solid\"\n",
        "    })\n",
        ")\n",
        "\n",
        "# Call the matplotlib engine to avoid Playwright/Chrome errors or mismatch\n",
        "dfi.export(styled, \"dataset_preview.png\", table_conversion=\"matplotlib\")\n",
        "\n",
        "# Load the generated preview of the dataset\n",
        "print(\"Saved: dataset_preview.png\")\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
