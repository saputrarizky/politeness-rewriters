{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Information**\n",
        "\n",
        "**• Members:** 사푸트라 (Saputra Rizky Johan), 바트오르식 (Butemj Bat-Orshikh), 쉬슈잔 (Shu Xian Chow)\n",
        "\n",
        "**• Institution:** Seoul National University, South Korea\n",
        "\n",
        "**• Course:** 2025-2 Introduction to Natural Language Processing (001)\n",
        "\n",
        "**• Instructors:** 황승원 (Prof), 김종윤(TA), 한상은 (TA)\n",
        "\n",
        "**• Project:** Classifier-Guided Politeness Rewriting via Span Detection and Controlled Text Generation\n",
        "\n",
        "**• Corpus:** Stanford Politeness Corpus (Convokit)"
      ],
      "metadata": {
        "id": "z8RcTq80em7O"
      },
      "id": "z8RcTq80em7O"
    },
    {
      "cell_type": "markdown",
      "id": "3834e0ef",
      "metadata": {
        "id": "3834e0ef"
      },
      "source": [
        "\n",
        "# **Politeness Rewriter - Colab Runner**\n",
        "\n",
        "**• Note:** This notebook runs the **politeness-rewriter** project end-to-end in Google Colab with the current version pins:\n",
        "- Keep **NumPy ≥ 2** (for spaCy/thinc/Convokit)\n",
        "- Pin **Transformers 4.44.2** (supports `evaluation_strategy`)\n",
        "- Keep **pandas==2.2.2** (to match google-colab)\n",
        "- Use **spacy 3.8.x** + **Convokit 3.4.1** (Py3.12-friendly wheels)\n",
        "\n",
        "**• Pipeline:** Drive mount → unzip → fix package layout → install deps → download data → train classifier → sanity infer → rewrite → quick eval → *(optional)* Gradio demo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Case 1. Run via Google Drive**"
      ],
      "metadata": {
        "id": "6kbNg3ByP711"
      },
      "id": "6kbNg3ByP711"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.1. Check GPU and Mount Drive**\n",
        "\n",
        "**• Purpose:**\n",
        "- Execute the associated step in the Colab workflow and detect the available GPU.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes)."
      ],
      "metadata": {
        "id": "A4vposfcRGFJ"
      },
      "id": "A4vposfcRGFJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "663c6c13",
      "metadata": {
        "id": "663c6c13"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Check the available GPU\n",
        "!nvidia-smi || echo \"No GPU visible (training will still work, just slower).\"\n",
        "\n",
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.2. Locate and load the project file**\n",
        "\n",
        "**• Purpose:**\n",
        "- Change the working directory and prepare project paths for running.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes).\n",
        "- Adjusts the project name accordingly if the file is in a different name."
      ],
      "metadata": {
        "id": "ZuV0KYJpShJ1"
      },
      "id": "ZuV0KYJpShJ1"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5f2bd2b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f2bd2b9",
        "outputId": "09cc1357-ffd8-4afa-8803-282a858b73a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using ZIP: /content/drive/MyDrive/politeness-rewriters.zip\n",
            "/content\n",
            "Archive:  /content/drive/MyDrive/politeness-rewriters.zip\n",
            "   creating: /content/politeness-rewriters/\n",
            "  inflating: /content/__MACOSX/._politeness-rewriters  \n",
            "  inflating: /content/politeness-rewriters/.DS_Store  \n",
            "  inflating: /content/__MACOSX/politeness-rewriters/._.DS_Store  \n",
            "  inflating: /content/politeness-rewriters/requirements.txt  \n",
            "   creating: /content/politeness-rewriters/out/\n",
            " extracting: /content/politeness-rewriters/README.md  \n",
            "  inflating: /content/politeness-rewriters/app.py  \n",
            "  inflating: /content/__MACOSX/politeness-rewriters/._app.py  \n",
            "   creating: /content/politeness-rewriters/data/\n",
            "   creating: /content/politeness-rewriters/src/\n",
            "  inflating: /content/politeness-rewriters/src/rerank.py  \n",
            "  inflating: /content/politeness-rewriters/src/baseline_rules.py  \n",
            "  inflating: /content/politeness-rewriters/src/rewrite_t5.py  \n",
            "  inflating: /content/politeness-rewriters/src/.DS_Store  \n",
            "  inflating: /content/__MACOSX/politeness-rewriters/src/._.DS_Store  \n",
            "  inflating: /content/politeness-rewriters/src/config.py  \n",
            " extracting: /content/politeness-rewriters/src/__init__.py  \n",
            "  inflating: /content/politeness-rewriters/src/download_data.py  \n",
            "  inflating: /content/politeness-rewriters/src/classifier_infer.py  \n",
            "  inflating: /content/politeness-rewriters/src/classifier_train.py  \n",
            "  inflating: /content/politeness-rewriters/src/pipeline.py  \n",
            "  inflating: /content/politeness-rewriters/src/eval.py  \n"
          ]
        }
      ],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Declare the names of the zip file in your drive (Adjust if necessary)\n",
        "ZIP_CANDIDATES = [\n",
        "    \"/content/drive/MyDrive/politeness-rewriters.zip\",\n",
        "    \"/content/drive/MyDrive/politeness-rewritters.zip\",\n",
        "    \"/content/drive/MyDrive/Downloads/politeness-rewriter.zip\",\n",
        "    \"/content/drive/MyDrive/Downloads/politeness-rewritter.zip\",\n",
        "    \"/content/drive/MyDrive/politeness-rewriter.zip\",\n",
        "    \"/content/drive/MyDrive/politeness-rewritter.zip\",\n",
        "]\n",
        "\n",
        "# Locate the politeness rewriter zip file\n",
        "zip_path = None\n",
        "import os\n",
        "for cand in ZIP_CANDIDATES:\n",
        "    if os.path.exists(cand):\n",
        "        zip_path = cand; break\n",
        "if zip_path is None:\n",
        "    raise FileNotFoundError(\"Could not find the project ZIP. Set `zip_path` manually to its location in Drive.\")\n",
        "\n",
        "# Display the zip file and its path\n",
        "print(\"Using ZIP:\", zip_path)\n",
        "\n",
        "# Unzip the file into the content directory (Adjust if necessary)\n",
        "%cd /content\n",
        "!unzip -o \"$zip_path\" -d /content\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.3. Project Normalization**\n",
        "\n",
        "**• Purpose:**\n",
        "- Normalize the project folder name, ensure the src is a package and remove and bundled env/.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes).\n",
        "- Adjusts the project name accordingly if the file is in a different name."
      ],
      "metadata": {
        "id": "HLT7CuA5T9rA"
      },
      "id": "HLT7CuA5T9rA"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "77137333",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77137333",
        "outputId": "835f9a77-ca92-492e-df50-ac1e42684847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project path: /content/politeness-rewriters\n",
            "/content/politeness-rewriters\n",
            "src/__init__.py OK\n"
          ]
        }
      ],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Setup the necessary modules or packages\n",
        "import os, shutil, sys\n",
        "\n",
        "# Normalize the project folder name\n",
        "proj_path = None\n",
        "for cand in [\"/content/politeness-rewriters\", \"/content/politeness-rewritters\"]:\n",
        "    if os.path.isdir(cand):\n",
        "        proj_path = cand; break\n",
        "if proj_path is None:\n",
        "    for root, dirs, files in os.walk(\"/content\"):\n",
        "        if \"src\" in dirs and \"requirements.txt\" in files:\n",
        "            proj_path = root; break\n",
        "if proj_path is None:\n",
        "    raise RuntimeError(\"Could not locate the project folder after unzipping.\")\n",
        "\n",
        "# Rename the misspelling to a canonical folder\n",
        "if proj_path.endswith(\"politeness-rewritters\"):\n",
        "    target = \"/content/politeness-rewriters\"\n",
        "    if os.path.isdir(target):\n",
        "        shutil.rmtree(target, ignore_errors=True)\n",
        "    os.rename(proj_path, target)\n",
        "    proj_path = target\n",
        "\n",
        "print(\"Project path:\", proj_path)\n",
        "%cd \"$proj_path\"\n",
        "\n",
        "# Remove the bundled venv if present\n",
        "if os.path.isdir(\"env\"):\n",
        "    print(\"Removing bundled env/\"); shutil.rmtree(\"env\", ignore_errors=True)\n",
        "\n",
        "# Ensure src is a package\n",
        "os.makedirs(\"src\", exist_ok=True)\n",
        "if os.path.exists(\"src/init.py\") and not os.path.exists(\"src/__init__.py\"):\n",
        "    os.rename(\"src/init.py\", \"src/__init__.py\")\n",
        "if not os.path.exists(\"src/__init__.py\"):\n",
        "    open(\"src/__init__.py\", \"a\").close()\n",
        "print(\"src/__init__.py OK\")\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.4. Install Dependencies**\n",
        "\n",
        "**• Purpose:**\n",
        "- Install the necessary Python dependencies required to load and run the Politeness Rewriter project.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes).\n",
        "- Adjusts the dependencies only when it is necessary. Otherwise, keep the current dependencies."
      ],
      "metadata": {
        "id": "iW-mv3i_VXIX"
      },
      "id": "iW-mv3i_VXIX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de00fa20",
      "metadata": {
        "id": "de00fa20"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "%%bash\n",
        "set -e\n",
        "\n",
        "# Modernize toolchain\n",
        "python -m pip install -U pip setuptools wheel\n",
        "\n",
        "# Foundation pins (Keep NumPy >=2 and pandas==2.2.2 for Colab harmony)\n",
        "python -m pip install -U \"numpy>=2.0,<3\" \"pandas==2.2.2\"\n",
        "\n",
        "# Core HF stack (Transformers 4.44.2 supports `evaluation_strategy`)\n",
        "python -m pip install -U \"transformers==4.44.2\" \"tokenizers==0.19.1\" \"accelerate==0.33.0\"\n",
        "\n",
        "# NLP, metrics, utils\n",
        "python -m pip install -U \"datasets>=2.20.0\" \"sentence-transformers>=3.0.1\"   \"scikit-learn>=1.3.0\" \"tqdm>=4.66.0\" \"bert-score>=0.3.13\" \"evaluate>=0.4.1\"   \"gradio>=4.36.1\" \"nltk>=3.8.1\" \"pyyaml>=6.0\"\n",
        "\n",
        "# Spacy 3.8.x (Py3.12 wheels) + Convokit 3.4.1\n",
        "python -m pip install -U \"spacy>=3.8,<3.9\" \"convokit==3.4.1\"\n",
        "\n",
        "# If repo has requirements.txt, install it without deps so we don't downgrade the pinned stack.\n",
        "if [ -f requirements.txt ]; then\n",
        "  python -m pip install --no-deps -r requirements.txt || true\n",
        "fi\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.5. Cache the HuggingFace models (Optional)**\n",
        "\n",
        "**• Purpose:**\n",
        "- cache HF models to Drive to avoid redownloading. However, this step is optional.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes)."
      ],
      "metadata": {
        "id": "7Mq4-yE5WPmd"
      },
      "id": "7Mq4-yE5WPmd"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "03d8f735",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03d8f735",
        "outputId": "cbf1894e-eb11-425c-f474-ddc415e142b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HF cache: /content/drive/MyDrive/hf_cache\n"
          ]
        }
      ],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Setup the necessary modules or packages\n",
        "import os\n",
        "\n",
        "# Declare the directory for caching the HF models into Drive\n",
        "os.environ[\"HF_HOME\"] = \"/content/drive/MyDrive/hf_cache\"\n",
        "os.environ[\"TRANSFORMERS_CACHE\"] = \"/content/drive/MyDrive/hf_cache\"\n",
        "os.makedirs(os.environ[\"HF_HOME\"], exist_ok=True)\n",
        "print(\"HF cache:\", os.environ[\"HF_HOME\"])\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.6. Patching to utilize the dataset keys**\n",
        "\n",
        "**• Purpose:**\n",
        "- Patch the dataset directory, specifically src/download_data.py, in order to to use the correct dataset key.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes)."
      ],
      "metadata": {
        "id": "OSC2ZRIqXI_7"
      },
      "id": "OSC2ZRIqXI_7"
    },
    {
      "cell_type": "code",
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Setup the necessary modules or packages\n",
        "from pathlib import Path\n",
        "\n",
        "# Declare the directory and associated paths\n",
        "p = Path(\"src/download_data.py\")\n",
        "s = p.read_text()\n",
        "\n",
        "# Patch the download_data.py module\n",
        "s2 = s.replace('download(\"stanford-politeness-corpus\")',\n",
        "               'download(\"stack-exchange-politeness-corpus\")')\n",
        "p.write_text(s2)\n",
        "print(\"Patched download_data.py -> 'stack-exchange-politeness-corpus'\")\n",
        "## ---------------------------------------- END ----------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjug4EvMK70o",
        "outputId": "4e9b4a20-4de6-4e7d-cdf4-8fb86342ac51"
      },
      "id": "wjug4EvMK70o",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patched download_data.py -> 'stack-exchange-politeness-corpus'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.7. Download the Stanford Politeness data via ConvoKit**\n",
        "\n",
        "**• Purpose:**\n",
        "- Run download_data.py with the stack-exchange-politeness-corpus.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes)."
      ],
      "metadata": {
        "id": "-imS50mRYFd_"
      },
      "id": "-imS50mRYFd_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29e3e7b5",
      "metadata": {
        "id": "29e3e7b5"
      },
      "outputs": [],
      "source": [
        "\n",
        "## --------------------------------------- START ---------------------------------------\n",
        "# Download the Stanford Politeness data and run the dataset loader for training\n",
        "%cd \"$proj_path\"\n",
        "!python src/download_data.py\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.8. Training the classifier**\n",
        "\n",
        "**• Purpose:**\n",
        "- Train the classifier through classifier_train.py with the training parameters (adjust the number of epochs, batch size and learning rate for better results)\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes).\n",
        "- Adjust higher number of epochs and controlled learning rate (preferrably lower if the number of epochs is high) for better results without overfitting the data."
      ],
      "metadata": {
        "id": "DYOLNIprYnik"
      },
      "id": "DYOLNIprYnik"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32c9fd1e",
      "metadata": {
        "id": "32c9fd1e"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Train the classifier (Please adjust the parameters for better training results)\n",
        "%cd \"$proj_path\"\n",
        "!python src/classifier_train.py \\\n",
        "  --data_path data/train.jsonl \\\n",
        "  --save_dir out/classifier/model \\\n",
        "  --epochs 2 \\\n",
        "  --batch_size 16 \\\n",
        "  --lr 5e-5\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.9. Run inference and sanity check**\n",
        "\n",
        "**• Purpose:**\n",
        "- Run the inference and execute sanity checks from the training results through the classifier_infer.py module.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes)."
      ],
      "metadata": {
        "id": "zA1yQ9TJZowQ"
      },
      "id": "zA1yQ9TJZowQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66e44325",
      "metadata": {
        "id": "66e44325"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# 3) Quick inference sanity check\n",
        "%cd \"$proj_path\"\n",
        "!python src/classifier_infer.py --text \"send me the report now\"\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.10. End-to-end rewriting**\n",
        "\n",
        "**• Purpose:**\n",
        "- Rewrite the sample input with the outputs using the trained classifier (Adjust the training parameters to achieve the best end to end results) through the pipeline.py module.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes)."
      ],
      "metadata": {
        "id": "DvIzLaZAames"
      },
      "id": "DvIzLaZAames"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9d8ad1e",
      "metadata": {
        "id": "a9d8ad1e"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Execute the end-to-end rewriting\n",
        "%cd \"$proj_path\"\n",
        "!python src/pipeline.py --text \"send me the report now asap\"\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.11. Evaluate the model with samples**\n",
        "\n",
        "**• Purpose:**\n",
        "- Evaluate the dataset with a specified number of samples (Set more samples for more coherent results) through the eval.py module.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes).\n",
        "- Adjust the number of samples for better coherence and accuracy (higher number of samples is preferred)."
      ],
      "metadata": {
        "id": "rNhsJaXebOVV"
      },
      "id": "rNhsJaXebOVV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d943248e",
      "metadata": {
        "id": "d943248e"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Evaluate the model with the specified number of samples\n",
        "%cd \"$proj_path\"\n",
        "!python src/eval.py --n 20 --save_csv out/eval_samples.csv\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.12. Lauch the gradio demo**\n",
        "\n",
        "**• Purpose:**\n",
        "- Launching a gradio demo as a visualizer and actual running with customized or personalized sentences via the app.py module.\n",
        "\n",
        "**• Note:**\n",
        "- Make sure that the previous steps are completed without any errors (Exception for subprocess errors).\n",
        "- Re-run this cell if you changed any configuration or file paths (Make sure to document these changes).\n",
        "- Execute the app via terminal using cd politeness-rewriters (or other directory names) and python app.py for retrieving the public url host."
      ],
      "metadata": {
        "id": "tM6bwKAEcBvR"
      },
      "id": "tM6bwKAEcBvR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd5bd6d2",
      "metadata": {
        "id": "dd5bd6d2"
      },
      "outputs": [],
      "source": [
        "## --------------------------------------- START ---------------------------------------\n",
        "# Launch the Gradio demo\n",
        "%cd \"$proj_path\"\n",
        "!python app.py\n",
        "## ---------------------------------------- END ----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Case 2. Run via GitHub**\n",
        "\n",
        "• To be added soon"
      ],
      "metadata": {
        "id": "ewUm6pDNc92J"
      },
      "id": "ewUm6pDNc92J"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}